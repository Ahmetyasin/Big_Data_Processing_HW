{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.4/spark-3.2.4-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.4-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "O98eyBCKBgP3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.4-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "3AVcC8ISLwSv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ],
      "metadata": {
        "id": "13OqbHeOzg24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9762ce8a-cae0-4565-ab0b-d48bb9ccc434"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.2.4-bin-hadoop3.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ä°mporting libraries\n",
        "import math\n",
        "from pyspark import SparkContext"
      ],
      "metadata": {
        "id": "KjQyWyVYTigN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SparkContext\n",
        "sparkCtx = SparkContext.getOrCreate()\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/DollarDataset.txt\"\n",
        "data = sparkCtx.textFile(file_path)\n",
        "\n",
        "# Filter out lines that do not have the expected format and convert the third column to float\n",
        "def parse_line(line):\n",
        "    parts = line.split(\"\\t\")\n",
        "    try:\n",
        "        date = parts[1]\n",
        "        value = float(parts[2].replace(',', '.'))\n",
        "        return (date, value)\n",
        "    except (IndexError, ValueError):\n",
        "        return None\n",
        "\n",
        "structured_data = data.map(parse_line).filter(lambda x: x is not None)\n",
        "\n",
        "# Collect the data as a list\n",
        "collected_data = structured_data.collect()\n",
        "\n",
        "percentage_increases = []\n",
        "\n",
        "# Loop through the collected data and compute percentage increases\n",
        "for i in range(1, len(collected_data)):\n",
        "    prev_day = collected_data[i-1]\n",
        "    current_day = collected_data[i]\n",
        "    increase = 100 * (current_day[1] - prev_day[1]) / prev_day[1]\n",
        "    percentage_increases.append(((current_day[0], prev_day[0]), increase))\n",
        "\n",
        "# Sort to get top 5 increases\n",
        "sorted_increases = sorted(percentage_increases, key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "for record in sorted_increases:\n",
        "    print(f\"Date: {record[0][0]} Previous Date: {record[0][1]} Percentage Increase: {record[1]:.2f}%\")\n",
        "\n",
        "# Stop the SparkContext\n",
        "sparkCtx.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHkGgYDw7wyg",
        "outputId": "a8354a2e-3a90-4cc7-f1c9-ee6b0c5aa540"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date: 22-08-1960 Previous Date: 19-08-1960 Percentage Increase: 221.43%\n",
            "Date: 25-01-1980 Previous Date: 24-01-1980 Percentage Increase: 100.00%\n",
            "Date: 10-08-1970 Previous Date: 07-08-1970 Percentage Increase: 65.00%\n",
            "Date: 12-06-1979 Previous Date: 11-06-1979 Percentage Increase: 32.08%\n",
            "Date: 01-03-1978 Previous Date: 28-02-1978 Percentage Increase: 29.87%\n"
          ]
        }
      ]
    }
  ]
}